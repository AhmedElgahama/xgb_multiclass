#!/usr/bin/env Rscript

## ---- Initialising libraries ----
library(tibble)
library(tidyr)
library(readr)
library(purrr)
library(dplyr)
library(stringr)
library(lubridate)
library(glue)
library(zeallot)
library(xgboost)
library(pROC)
library(forcats)
library(rjson)
library(caTools)
library(imputeTS)
library(CatEncoders)
options(dplyr.summarise.inform = FALSE)


## Script that holp helper functions
source('algorithm/0.common_funcs.R')


## get the json file for the schema
schema <-
  glue('/opt/model_inputs_outputs/inputs/schema/',
       list.files(path = "/opt/model_inputs_outputs/inputs/schema"))

## Get the training data file
data   <-
  glue(
    '/opt/model_inputs_outputs/inputs/data/training/',
    list.files(path = "/opt/model_inputs_outputs/inputs/data/training/")
  )

## Get the hyperparameters file
# hpt   <-
#   glue(
#     '/opt/model_inputs_outputs/model/model_config/',
#     list.files(path = "/opt/model_inputs_outputs/model/model_config/")
#   )

trainer <- function(schema_path, data_path)
{
  
  
   ## Reading model hyperparameters
  # hpt <- fromJSON(file = hpt_path)
  
  eta_p       = 0.3
  max_depth_p = 5
  nrounds_p   = 1000
  # for (hp in hpt$parameters)
  # {
  #   if (hp['name'] == 'nrounds')
  #   {
  #     nrounds_p   <- hp[['default']]
  #   } else if (hp['name'] == 'eta')
  #   {
  #     eta_p       <- hp[['default']]
  #   } else if (hp['name'] == 'max_depth')
  #   {
  #     max_depth_p <- hp[['default']]
  #   }
  # }
  
  
  hypergrid <- expand_grid(
    eta       = eta_p,
    max_depth = max_depth_p,
    nrounds   = nrounds_p,
    auc       = 0
  )

  ## Reading schema
  file <- fromJSON(file = schema_path)
  
  ## Saving id, target, and target class in variables
  id_column    <-
    file$id$name
  target_column       <-
    file$target$name
  target_classes <-
    file$target$classes
  features <- 
    file$features
  
  
  ## Splitting data into two categories (Numerical and Categorical)
  exp_vars            <- c()
  variables_to_encode <- c()
  variables_numeric     <- c()
  for (field in features)
  {
    type <- field[['dataType']]
    name <- field[['name']]
    
    if (type == 'CATEGORICAL')
    {
      variables_to_encode <- c(variables_to_encode, name)
      exp_vars           <- c(exp_vars, name)
    } else
    {
      exp_vars           <- c(exp_vars, name)
      variables_numeric    <- c(variables_numeric, name)
    }
  }
  
  
  ## Reading training data and dropping any row with no lablel
  
  full_data <-
    read_csv(data_path) %>% drop_na(target_column)

print("step 1")

  ## Changing datatype of categorical and numeric variables as received from json file
  full_data[variables_to_encode] <-
    sapply(full_data[variables_to_encode], as.character)
  full_data[variables_numeric]   <-
    sapply(full_data[variables_numeric], as.numeric)
  
  id     <- full_data[, id_column]
  target <- full_data[, target_column]

print("step 2")
  ## Impute missing values
  ## With mean for numeric fields
  ## And mode for categorical fields
  full_data_numeric <-
    full_data %>% select(variables_numeric) %>% na_mean(option = "mean")
  full_data_categorical <-
    full_data  %>% select(variables_to_encode) %>%
    mutate(across(everything(), ~ replace_na(.x, calc_mode(.x))))
  
  
  full_data <-
    cbind(id, full_data_numeric, full_data_categorical, target)
  
  print("step 3")
  

  
  encodings <- list()
  
  if (length(variables_to_encode) != 0)
  {
    full_data_categorical <-
      full_data  %>% select(variables_to_encode) %>%
      mutate(across(everything(), ~ replace_na(.x, calc_mode(.x))))
    
    for (i in variables_to_encode) {
      #define original categorical labels
      encoding = LabelEncoder.fit(full_data_categorical[[i]])
      encodings[[i]] <- encoding
      #convert labels to numeric values
      full_data_categorical[[i]] = transform(encoding, full_data_categorical[[i]])
    }
    exp_vars <-
      c(full_data_categorical %>% colnames(),
        full_data_numeric %>% colnames())
    
    full_data <-
      cbind(id, full_data_numeric, full_data_categorical, target)
    
  } else{
    full_data_categorical <- NULL
    encodings <- NULL
    exp_vars <- full_data_numeric %>% colnames()
    full_data <-
      cbind(id, full_data_numeric, target)
    
  }


print("step 4")
  colnames(full_data)[colnames(full_data)==get('target_column')] = "label"
  
  
  full_data$label <- as.factor(full_data$label)
  
  species = full_data$label
  label = as.integer(full_data$label)-1
  
  
  
  
  full_data$label = NULL
  
  print("step 5")
  
  ## Splitting data to train and validation. 70% and 30%
  set.seed(6789)
  # split = sample.split(full_data[[target_column]], SplitRatio = 0.7)
  # df_train_split = subset(full_data, split == TRUE)
  # df_val_split = subset(full_data, split == FALSE)
  n = nrow(full_data)
  train.index = sample(n,floor(0.75*n))
  df_train = as.matrix(full_data[train.index,])
  train.label = label[train.index]
  df_val = as.matrix(full_data[-train.index,])
  test.label = label[-train.index]
  
  ## Encoding categorical variables
  # categories <- full_data[target_column] %>% distinct()
  # categories <- categories[[1]]
  # other_class <- categories[!(categories %in% target_class)]
  
  
  print("step 6")
  
  # colnames(df_train_split)[colnames(df_train_split)==get('target_column')] = "label"
  # colnames(df_val_split)[colnames(df_val_split)==get('target_column')] = "label"
  

  
  # df_train <-
  #   df_train_split %>% mutate(y = label)
  # 
  # df_val   <-
  #   df_val_split %>% mutate(y = label) 
  
  # df_train["y"][df_train["y"] == get("target_class")] <- TRUE
  # df_train["y"][df_train["y"] == get("other_class")] <- FALSE
  # df_val["y"][df_val["y"] == get("target_class")] <- TRUE
  # df_val["y"][df_val["y"] == get("other_class")] <- FALSE
  
  # df_train$y <- df_train$y %>% as.logical()
  # df_val$y <- df_val$y %>% as.logical()
  # 

  
  
  # df_train["label"][df_train["label"] == get("target_class")] <- 1
  # df_train["label"][df_train["label"] == get("other_class")] <- 0
  # df_val["label"][df_val["label"] == get("target_class")] <- 1
  # df_val["label"][df_val["label"] == get("other_class")] <- 0
  num_class = length(unique(species))
  print("step 7")
  ## Training model model
  ## The return of the function is list with model
  trained_model <-
    trainer_func(
      train_set      = df_train,
      validation_set = df_val,
      train_labels = train.label,
      val_labels = test.label,
      explanatory_variables = exp_vars ,
      
      hypergrid = hypergrid,
      num_class = num_class,
      species= species
    )
  
  
  ## Saving other features with the model to use in test and serve
  trained_model$exp_vars <- exp_vars
  # trained_model$target_class <- target_class
  # trained_model$other_class <- other_class
  trained_model$id_column <- id_column
  trained_model$variables_to_encode <- variables_to_encode
  trained_model$encodings <- encodings
  trained_model$num_class <- num_class
  trained_model$species <- species
  # trained_model$best_params %>% as.data.frame() %>% print()
  print("*"*50)  
  print("*"*50)

  trained_model %>% write_rds('/opt/model_inputs_outputs/model/artifacts/model.rds')
}

tryCatch(               
  
  # Specifying expression
  expr = {                     
    trainer(schema, data)
  },
  # Specifying error message
  error = function(e){         
    write(e %>% as.character(),file="/opt/model_inputs_outputs/outputs/errors/train_failure.txt",append=FALSE)
  }
)

